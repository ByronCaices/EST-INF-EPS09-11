---
title: "EP11-respuesta-equipo-2"
date: "2024-12-16"
output: html_document
---

```{r setup, include=FALSE}
options(repos = c(CRAN = "https://cran.rstudio.com/"))

if (!requireNamespace('tidyverse', quietly = TRUE)){
  install.packages('tidyverse')
}
library(tidyverse)
if (!requireNamespace('ggpubr', quietly = TRUE)){
  install.packages('ggpubr')
}
library(car)
if (!requireNamespace('car', quietly = TRUE)){
  install.packages('car')
}
library(ggpubr)
if (!requireNamespace('ez', quietly = TRUE)){
  install.packages('ez')
}
library(ez)
if (!requireNamespace('RVAideMemoire', quietly = TRUE)){
  install.packages('RVAideMemoire')
}
library(RVAideMemoire)
if (!requireNamespace('rcompanion', quietly = TRUE)){
  install.packages('rcompanion')
}
library(rcompanion)
if (!requireNamespace('dplyr', quietly = TRUE)){
  install.packages('dplyr')
}
library(dplyr)
if (!requireNamespace('WRS2', quietly = TRUE)){
  install.packages('WRS2')
}
library(WRS2)
if (!requireNamespace('caret', quietly = TRUE)){
  install.packages('caret')
}
library(caret)
if (!requireNamespace('leaps', quietly = TRUE)){
  install.packages('leaps')
}
library(leaps)
```

#### CONTEXTO
#### Usando los datos de medidas anatómicas recolectados por Heinz et al. (2003) que ya conocimos en el ejercicio práctico anterior:

```{r datos}
datosGenerales <- read.csv2("EP09 Datos.csv")
head(datosGenerales)
```

#### Agregar variable EN e IMC.

```{r IMC}
datosGenerales[["IMC"]] = datosGenerales[["Weight"]] / ((datosGenerales[["Height"]]/100)^2)
datosSobrepeso = datosGenerales %>% filter(IMC < 23.2)
datosPesoNormal = datosGenerales %>% filter(IMC >= 23.2)
datosSobrepeso[["EN"]] = 1
datosPesoNormal[["EN"]] = 0
```
#### Definir la semilla a utilizar, que corresponde a los primeros cinco dígitos del RUN del integrante de mayor edad del equipo.
```{r seed}
set.seed(20915)
```
#### Seleccionar una muestra de 100 personas, asegurando que la mitad tenga estado nutricional “sobrepeso” y la otra mitad “no sobrepeso”.
```{r datos2}
datosSobrepeso = datosSobrepeso %>% sample_n(50, replace = FALSE)
datosPesoNormal = datosPesoNormal %>% sample_n(50, replace = FALSE)

datos = rbind(datosSobrepeso, datosPesoNormal)
```
#### Usando las herramientas del paquete leaps, realizar una búsqueda exhaustiva para seleccionar entre dos y ocho predictores que ayuden a estimar la variable Peso (Weight), obviamente sin considerar las nuevas variables IMC ni EN, y luego utilizar las funciones del paquete caret para construir un modelo de regresión lineal múltiple con los predictores escogidos y evaluarlo usando bootstrapping.
```{r modelo}
variable_a_predecir = "Weight"
variables_prohibidas = c("EN", "IMC")

modelo_dataframe<- datos %>% select(-(variables_prohibidas))
modelo_formula <- formula(paste(variable_a_predecir, ".", sep = " ~ "))
modelo_sets <- regsubsets(modelo_formula, data = modelo_dataframe, nbest = 2, nvmax = 8, method = "exhaustive")
modelo_sets_resumen <- summary(modelo_sets)
modelo_sets_i_mejor <- which.min(modelo_sets_resumen[["bic"]])
modelo_variables <- names(which(modelo_sets_resumen[["which"]][modelo_sets_i_mejor, ])[-1])

plot(modelo_sets)


cat("\nMejores predictores para el modelo de RLM 1:\n")
print(modelo_variables)
```
Usamos el paquete car y definimos la cantidad de repeticiones para bootstrap
```{r modelo 2}
texto <- paste(modelo_variables, collapse = " + ")
modelo_formula <- formula(paste(variable_a_predecir, texto, sep = " ~ "))

B = 1000
modelo_etrenado<- train(modelo_formula, data = modelo_dataframe, method = "lm",
                    trControl = trainControl(method = "boot", number = B))
modelo_final <- modelo_etrenado[["finalModel"]]

cat("Modelo de modelo de RLM 1:\n")
print(summary(modelo_final))
```
**Evaluar modelo usando bootstrapping**

Verificar condiciones para la confiabilidad del modelo

1- La varible de respuesta debe ser cuantitativa y continua

Como la variables de respuesta es peso, se cumple esta condición

2- Los predictores deben ser cuantitativos o diotomicos

Como las variables elegidas fueron Shoulder.Girth, Waist.Girth, Chest.Girth, Hip.Girth, Thigh.Girth, Forearm.Girth, Knee.Girth y Height son medidas, también se cumple esta condición

3- Los predictores deben tener algún grado de variabilidad

Como se puede observar, ningun predictor tiene desviación estandar 0

Multicolinealidad
Verificamos la multicolinealidad antes de seguir evaluando el modelo
```{r}
cat("Multicolinealidad\n")
print(vif(modelo_final))
```
Para evitar problemas eliminamos el predictor Chest.Girth, ya que tiene un VIF muy preocupante y volvemos a generar el modelo y evaluar la multicolinealidad
```{r}
modelo_variables = modelo_variables[-2]
texto <- paste(modelo_variables, collapse = " + ")
modelo_formula <- formula(paste(variable_a_predecir, texto, sep = " ~ "))

B = 1000
modelo_etrenado<- train(modelo_formula, data = modelo_dataframe, method = "lm",
                    trControl = trainControl(method = "boot", number = B))
modelo_final <- modelo_etrenado[["finalModel"]]

cat("Modelo de modelo de RLM 1:\n")
print(summary(modelo_final))

print(vif(modelo_final))
```
Como se puede ver el predictor Shoulder.Girth  tiene un VIF preocupante por lo que repetimos el procedimiento anterior con esta variable
```{r}
modelo_variables = modelo_variables[-1]
texto <- paste(modelo_variables, collapse = " + ")
modelo_formula <- formula(paste(variable_a_predecir, texto, sep = " ~ "))

B = 1000
modelo_etrenado<- train(modelo_formula, data = modelo_dataframe, method = "lm",
                    trControl = trainControl(method = "boot", number = B))
modelo_final <- modelo_etrenado[["finalModel"]]

cat("Modelo de modelo de RLM 1:\n")
print(summary(modelo_final))

print(vif(modelo_final))

```
Como se puede ver el predictor Hip.Girth  tiene un VIF casi preocupante por lo que repetimos el procedimiento anterior con esta variable
```{r}
modelo_variables = modelo_variables[-2]
texto <- paste(modelo_variables, collapse = " + ")
modelo_formula <- formula(paste(variable_a_predecir, texto, sep = " ~ "))

B = 1000
modelo_etrenado<- train(modelo_formula, data = modelo_dataframe, method = "lm",
                    trControl = trainControl(method = "boot", number = B))
modelo_final <- modelo_etrenado[["finalModel"]]

cat("Modelo de modelo de RLM 1:\n")
print(summary(modelo_final))

print(vif(modelo_final))

```
Ahora los predictores tienen VIF aceptables, además que podemos observar que el modelo reduce la varianza en un 96,5% aproximadamente respecto al modelo nulo

Además procedemos a verificar las demás condiciones a partir del gráfico de residuos

```{r rp}
modelo_lm = lm(modelo_formula, modelo_dataframe)
residualPlots(modelo_lm)
ncvTest(modelo_lm)
```
Podemos ver que la variable Waist.Girth y Knee.Girth obtiene un resultado significativo en la prueba de curvatura por lo que procedemos a graficar las relaciones de estas variables para comprobar la linealidad de estas variables respecto a la variable de respuesta

```{r cr}
crPlots(modelo_lm)
```
Se ven dentro de lo normal, considerando que en el gráfico de Knee.Girth la curvatura puede estar producida por los valores extremos influyentes.

Homocedasticidad
```{r homo}
cat("\nHomocedastididad Waist.Girth\n")
ncvTest(lm(Weight ~ Waist.Girth, modelo_dataframe))
cat("\nHomocedastididad Thigh.Girth\n")
ncvTest(lm(Weight ~ Thigh.Girth, modelo_dataframe))
cat("\nHomocedastididad Forearm.Girth\n")
ncvTest(lm(Weight ~ Forearm.Girth, modelo_dataframe))
cat("\nHomocedastididad Knee.Girth\n")
ncvTest(lm(Weight ~ Knee.Girth, modelo_dataframe))
cat("\nHomocedastididad Height\n")
ncvTest(lm(Weight ~ Height, modelo_dataframe))
```
```{r graficos homo}
marginalModelPlots(modelo_lm, sd = TRUE, 
                   id = list(method = "r", n = 3, cex = 0.7, location = "lr"),
                   col = "steelblue", pch = 20, col.line = c("steelblue","red"))
```
A partir de los gráficos y del ncvTest podemosobservar que e la mayoría de las variables se obtiene un nivel adecuado de homocedasticidad, a excepcion de la variable Forearm.Girth, pero posiblemente este resultado se ve afectado por lo valores atipicos que se pueden ver en el gráfico de la variable mencionada anteriormente
```{r atipicos}
modelo_influencia = influencePlot(modelo_lm, id = list(n = 3))
print(modelo_influencia)

```
Como se puede observar las observaciones 92 y 96 están bastante alejados y presentan una distancia de Cook alta, además, las observaciones 69, 71 y 79 poseen un alto hat value por lo que también pueden estar influenciando el modelo, cabe notar que ninguna observación está fuera de las 3 metricas, para evaluar el efecto de estas observaciones usaremos la función compareCoefs().

```{r}
influencia_ids <- as.integer(rownames(modelo_influencia))
rlm1_comp_f <- function(s) {
  mat <- eval(bquote(compareCoefs(modelo_lm, update(modelo_lm, subset = -.(s)), print = FALSE)))
  rownames(mat) <- paste(rownames(mat), "sin caso", s)
  invisible(mat)
}
comparacion <- lapply(rlm1_inf_ids, rlm1_comp_f)
modelo_comparacion <- do.call(rbind, comparacion)

# Agregamos el cambio porcentual y encontramos el 25% superior
cambio_coeficiente <- abs((modelo_comparacion[, 1]-modelo_comparacion[, 3])/modelo_comparacion[, 1]) * 100
rlm1_comp <- cbind(modelo_comparacion, Cambio = cambio_coeficiente)
rlm1_coef_cambio_umb <- quantile(rlm1_coef_cambio, 0.75)

cat("Observaciones que generan cambios importantes de los coeficientes del modelo de RLM 1:\n")
printCoefmat(rlm1_comp[rlm1_coef_cambio >= rlm1_coef_cambio_umb, ])
```
Como podemos observar, el caso 25 es el más influyente debido a que provoca los mayores nniveles de cambio, depués es seguido por el caso 86 y luego por el 11, por lo que los eliminamos de los datos

```{r}
modelo_dataframe = modelo_dataframe[-c(25, 86, 11),]
modelo_lm = lm(modelo_formula, modelo_dataframe)

modelo_etrenado<- train(modelo_formula, data = modelo_dataframe, method = "lm",
                    trControl = trainControl(method = "boot", number = B))
modelo_final <- modelo_etrenado[["finalModel"]]

cat("Modelo de modelo de RLM 1 sin valores influyentes:\n")
print(summary(modelo_final))
```
Ahora toca recomprobar las condiciones para comprobar que el modelo sigue cumpliendo las condiciones de validación.

Linealidad de los predictores con la respuesta

Para comprobar esta condición podemos usar una prueba de curvatura o bien crPlots, comprobemos con los dos.
```{r}
residualPlots(modelo_lm)
crPlots(modelo_lm)
```
Con los valores de la prueba de curvatura entregados por la función residualPlots() observamos que la variable Knee.Girth tiene problemas con la curvatura, pero al ver el gráfico de esta variable de lña función crPlots(), observamos que esta curvatura puede estar dada por otros valores atipicos que no fueron eliminados, yaque quitando estos valores se puede observar que si se observa una relación aproximadamente lineal.

Homocedasticidad

Para comprobar esta condición podemos usar marginalModelPlots
```{r homo 2}
cat("\nHomocedastididad Waist.Girth\n")
ncvTest(lm(Weight ~ Waist.Girth, modelo_dataframe))
cat("\nHomocedastididad Thigh.Girth\n")
ncvTest(lm(Weight ~ Thigh.Girth, modelo_dataframe))
cat("\nHomocedastididad Forearm.Girth\n")
ncvTest(lm(Weight ~ Forearm.Girth, modelo_dataframe))
cat("\nHomocedastididad Knee.Girth\n")
ncvTest(lm(Weight ~ Knee.Girth, modelo_dataframe))
cat("\nHomocedastididad Height\n")
ncvTest(lm(Weight ~ Height, modelo_dataframe))
marginalModelPlots(modelo_lm, sd = TRUE, 
                   id = list(method = "r", n = 3, cex = 0.7, location = "lr"),
                   col = "steelblue", pch = 20, col.line = c("steelblue","red"))
```
Vemos que en todos los gráficos se ajusta bien la relación observada frente a la brindada por el modelom además de mostrar una varianza relativamente constante en cada caso.

Independencia de los residuos

Para esto usamos la función durbinWatsonTest que entrega el valor de autocorrelación del modelo

```{r auto}
print(durbinWatsonTest(modelo_lm))
```
Obtenemos que no hay evidencia suficiente para sospechar de una posible autocorrelación

Multicolinealidad

Para esta condición utilizamos la función vif

```{r multi}
print(vif(modelo_final))
```
Observamos que ninguna variable presenta un vif preocupante, por lo que no hay evidencia para sospechar de una posible multicolinealidad

Y como las comprobaciones fueron realizadas sobre el modelo sin casos influyentes procedemos a evaluar el desempeño del modelo

##### Desempeño
Veamos los niveles de error cometidos por el modelo de RLM 1 que hemos conseguido, analizando un histograma de los errores (RMSE) en cada repetición del bootstrapping y el reporte del error promedio generado por la función train().

```{r}
error_dataframe <- data.frame(RMSE = modelo_etrenado[["resample"]][["RMSE"]])
error_p <- gghistogram(error_dataframe, x = "RMSE", bins = 30)
print(error_p)


cat("Rendimiento del modelo de RLM 1:\n")
print(modelo_etrenado[["results"]])
print(describe(error_dataframe, trim = 0, skew = FALSE, IQR = TRUE), digits = 3)
```
Observamos que el modelo posee una bondad de ajuste de 0.954 aproximadamente, lo que es bastante bueno, además vemos que posee un error promedio de 2.9 ± 0.355 y vemos que la distrubución de error es aproximadamente simetrica también.

#### Haciendo un poco de investigación sobre el paquete caret, en particular cómo hacer Recursive Feature Elimination (RFE), construir un modelo de regresión lineal múltiple para predecir la variable IMC que incluya entre 10 y 20 predictores, seleccionando el conjunto de variables que maximice R2 y que use cinco repeticiones de validación cruzada de cinco pliegues para evitar el sobreajuste (obviamente no se debe considerar las variables Peso, Estatura ni estado nutricional –Weight, Height, EN respectivamente).
```{r modelo}

```
#### Usando RFE, construir un modelo de regresión logística múltiple para la variable EN que incluya el conjunto de predictores, entre dos y seis, que entregue la mejor curva ROC y que utilice validación cruzada dejando uno fuera para evitar el sobreajuste (obviamente no se debe considerar las variables Peso, Estatura –Weight y Height respectivamente– ni IMC).
```{r modelo}

```
#### Pronunciarse sobre la confiabilidad y el poder predictivo de los modelos obtenidos.
```{r modelo}

```