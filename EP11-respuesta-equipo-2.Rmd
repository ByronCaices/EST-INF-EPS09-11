---
title: "EP11-respuesta-equipo-2"
date: "2024-12-16"
output: html_document
---

```{r setup, include=FALSE}
options(repos = c(CRAN = "https://cran.rstudio.com/"))

if (!requireNamespace('tidyverse', quietly = TRUE)){
  install.packages('tidyverse')
}
library(tidyverse)
if (!requireNamespace('ggpubr', quietly = TRUE)){
  install.packages('ggpubr')
}
library(car)
if (!requireNamespace('car', quietly = TRUE)){
  install.packages('car')
}
library(ggpubr)
if (!requireNamespace('ez', quietly = TRUE)){
  install.packages('ez')
}
library(ez)
if (!requireNamespace('RVAideMemoire', quietly = TRUE)){
  install.packages('RVAideMemoire')
}
library(RVAideMemoire)
if (!requireNamespace('rcompanion', quietly = TRUE)){
  install.packages('rcompanion')
}
library(rcompanion)
if (!requireNamespace('dplyr', quietly = TRUE)){
  install.packages('dplyr')
}
library(dplyr)
if (!requireNamespace('WRS2', quietly = TRUE)){
  install.packages('WRS2')
}
library(WRS2)
if (!requireNamespace('caret', quietly = TRUE)){
  install.packages('caret')
}
library(caret)
if (!requireNamespace('leaps', quietly = TRUE)){
  install.packages('leaps')
}
library(leaps)
```

#### CONTEXTO
#### Usando los datos de medidas anatómicas recolectados por Heinz et al. (2003) que ya conocimos en el ejercicio práctico anterior:

```{r datos}
datosGenerales <- read.csv2("EP09 Datos.csv")
head(datosGenerales)
```

#### Agregar variable EN e IMC.

```{r IMC}
datosGenerales[["IMC"]] = datosGenerales[["Weight"]] / ((datosGenerales[["Height"]]/100)^2)
datosSobrepeso = datosGenerales %>% filter(IMC < 23.2)
datosPesoNormal = datosGenerales %>% filter(IMC >= 23.2)
datosSobrepeso[["EN"]] = 1
datosPesoNormal[["EN"]] = 0
```
#### Definir la semilla a utilizar, que corresponde a los primeros cinco dígitos del RUN del integrante de mayor edad del equipo.
```{r seed}
set.seed(20915)
```
#### Seleccionar una muestra de 100 personas, asegurando que la mitad tenga estado nutricional “sobrepeso” y la otra mitad “no sobrepeso”.
```{r datos2}
datosSobrepeso = datosSobrepeso %>% sample_n(50, replace = FALSE)
datosPesoNormal = datosPesoNormal %>% sample_n(50, replace = FALSE)

datos = rbind(datosSobrepeso, datosPesoNormal)
```
#### Usando las herramientas del paquete leaps, realizar una búsqueda exhaustiva para seleccionar entre dos y ocho predictores que ayuden a estimar la variable Peso (Weight), obviamente sin considerar las nuevas variables IMC ni EN, y luego utilizar las funciones del paquete caret para construir un modelo de regresión lineal múltiple con los predictores escogidos y evaluarlo usando bootstrapping.
```{r modelo}
variable_a_predecir = "Weight"
variables_prohibidas = c("EN", "IMC")

modelo_dataframe<- datos %>% select(-(variables_prohibidas))
modelo_formula <- formula(paste(variable_a_predecir, ".", sep = " ~ "))
modelo_sets <- regsubsets(modelo_formula, data = modelo_dataframe, nbest = 2, nvmax = 8, method = "exhaustive")
modelo_sets_resumen <- summary(modelo_sets)
modelo_sets_i_mejor <- which.min(modelo_sets_resumen[["bic"]])
modelo_variables <- names(which(modelo_sets_resumen[["which"]][modelo_sets_i_mejor, ])[-1])

plot(modelo_sets)


cat("\nMejores predictores para el modelo de RLM 1:\n")
print(modelo_variables)
```
Usamos el paquete car y definimos la cantidad de repeticiones para bootstrap
```{r modelo 2}
texto <- paste(modelo_variables, collapse = " + ")
modelo_formula <- formula(paste(variable_a_predecir, texto, sep = " ~ "))

B = 1000
modelo_etrenado<- train(modelo_formula, data = modelo_dataframe, method = "lm",
                    trControl = trainControl(method = "boot", number = B))
modelo_final <- modelo_etrenado[["finalModel"]]

cat("Modelo de modelo de RLM 1:\n")
print(summary(modelo_final))
```

Verificar condiciones para la confiabilidad del modelo

1- La varible de respuesta debe ser cuantitativa y continua

Como la variables de respuesta es peso, se cumple esta condición

2- Los predictores deben ser cuantitativos o diotomicos

Como las variables elegidas fueron Shoulder.Girth, Waist.Girth, Chest.Girth, Hip.Girth, Thigh.Girth, Forearm.Girth, Knee.Girth y Height son medidas, también se cumple esta condición

3- Los predictores deben tener algún grado de variabilidad

Como se puede observar, ningun predictor tiene desviación estandar 0

Multicolinealidad
Verificamos la multicolinealidad antes de seguir evaluando el modelo
```{r}
cat("Multicolinealidad\n")
print(vif(modelo_final))
```
Para evitar problemas eliminamos el predictor Chest.Girth, ya que tiene un VIF muy preocupante y volvemos a generar el modelo y evaluar la multicolinealidad
```{r}
modelo_variables = modelo_variables[-2]
texto <- paste(modelo_variables, collapse = " + ")
modelo_formula <- formula(paste(variable_a_predecir, texto, sep = " ~ "))

B = 1000
modelo_etrenado<- train(modelo_formula, data = modelo_dataframe, method = "lm",
                    trControl = trainControl(method = "boot", number = B))
modelo_final <- modelo_etrenado[["finalModel"]]

cat("Modelo de modelo de RLM 1:\n")
print(summary(modelo_final))

print(vif(modelo_final))
```
Como se puede ver el predictor Shoulder.Girth  tiene un VIF preocupante por lo que repetimos el procedimiento anterior con esta variable
```{r}
modelo_variables = modelo_variables[-1]
texto <- paste(modelo_variables, collapse = " + ")
modelo_formula <- formula(paste(variable_a_predecir, texto, sep = " ~ "))

B = 1000
modelo_etrenado<- train(modelo_formula, data = modelo_dataframe, method = "lm",
                    trControl = trainControl(method = "boot", number = B))
modelo_final <- modelo_etrenado[["finalModel"]]

cat("Modelo de modelo de RLM 1:\n")
print(summary(modelo_final))

print(vif(modelo_final))

```
Como se puede ver el predictor Hip.Girth  tiene un VIF casi preocupante por lo que repetimos el procedimiento anterior con esta variable
```{r}
modelo_variables = modelo_variables[-2]
texto <- paste(modelo_variables, collapse = " + ")
modelo_formula <- formula(paste(variable_a_predecir, texto, sep = " ~ "))

B = 1000
modelo_etrenado<- train(modelo_formula, data = modelo_dataframe, method = "lm",
                    trControl = trainControl(method = "boot", number = B))
modelo_final <- modelo_etrenado[["finalModel"]]

cat("Modelo de modelo de RLM 1:\n")
print(summary(modelo_final))

print(vif(modelo_final))

```
Ahora los predictores tienen VIF aceptables, además que podemos observar que el modelo reduce la varianza en un 96,5% aproximadamente respecto al modelo nulo

Además procedemos a verificar las demás condiciones a partir del gráfico de residuos

```{r}
modelo_lm = lm(modelo_formula, modelo_dataframe)
residualPlots(modelo_lm)
ncvTest(modelo_lm)
```
Se puede observar que no exiten patrones reconocibles en ningún gráfico, además de cumplir las otras condiciones, hecho qie por lo que queda
#### Haciendo un poco de investigación sobre el paquete caret, en particular cómo hacer Recursive Feature Elimination (RFE), construir un modelo de regresión lineal múltiple para predecir la variable IMC que incluya entre 10 y 20 predictores, seleccionando el conjunto de variables que maximice R2 y que use cinco repeticiones de validación cruzada de cinco pliegues para evitar el sobreajuste (obviamente no se debe considerar las variables Peso, Estatura ni estado nutricional –Weight, Height, EN respectivamente).
```{r modelo}

```
#### Usando RFE, construir un modelo de regresión logística múltiple para la variable EN que incluya el conjunto de predictores, entre dos y seis, que entregue la mejor curva ROC y que utilice validación cruzada dejando uno fuera para evitar el sobreajuste (obviamente no se debe considerar las variables Peso, Estatura –Weight y Height respectivamente– ni IMC).
```{r modelo}

```
#### Pronunciarse sobre la confiabilidad y el poder predictivo de los modelos obtenidos.
```{r modelo}

```